{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOh2m8lL9OEYmtwl95uNikV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thilakraj1708/ThilakRaj_5501/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "OrGmsZYbuy98",
        "outputId": "9580dc58-498d-4ba2-8979-a59c71afc653"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-2-b29c8249edaa>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-b29c8249edaa>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    from langchain_community.embeddings\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain_community.embeddings\n",
        "import HuggingFaceEmbeddings\n",
        "from\n",
        "langchain_community.vectorstores\n",
        "import FAISS\n",
        "from langchain.chains import\n",
        "RetrievalQA\n",
        "from langchain_google_genai\n",
        "import ChatGoogleGenerativeAI\n",
        "from Bio import Entrez\n",
        "\n",
        "# ---- CONFIG ----\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"your_gemini_api_key\"\n",
        "Entrez.email = \"your_email@example.com\"\n",
        "\n",
        "# ---- STEP 1: FETCH PUBMED ARTICLES ----\n",
        "def fetch_pubmed_articles(query, max_results=5):\n",
        "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
        "    record = Entrez.read(handle)\n",
        "    ids = record[\"IdList\"]\n",
        "    handle.close()\n",
        "\n",
        "    abstracts = []\n",
        "    for id in ids:\n",
        "        summary_handle = Entrez.efetch(db=\"pubmed\", id=id, rettype=\"abstract\", retmode=\"text\")\n",
        "        abstracts.append(summary_handle.read())\n",
        "        summary_handle.close()\n",
        "    return abstracts\n",
        "\n",
        "# ---- STEP 2: BUILD VECTORSTORE ----\n",
        "def build_vectorstore(docs):\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    vectorstore = FAISS.from_texts(docs, embedding=embeddings)\n",
        "    return vectorstore\n",
        "\n",
        "# ---- STEP 3: LOAD GEMINI PRO LLM ----\n",
        "def load_gemini_llm():\n",
        "    return ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)\n",
        "\n",
        "# ---- STEP 4: BUILD RAG CHAIN ----\n",
        "def build_qa_chain(vectorstore):\n",
        "    llm = load_gemini_llm()\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "    return RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
        "\n",
        "# ---- MAIN QA LOGIC ----\n",
        "def answer_question(query):\n",
        "    print(\"Searching PubMed...\")\n",
        "    docs = fetch_pubmed_articles(query)\n",
        "    if not docs:\n",
        "        return \"No relevant articles found.\"\n",
        "\n",
        "    print(\"Creating vector store...\")\n",
        "    vectorstore = build_vectorstore(docs)\n",
        "\n",
        "    print(\"Answering with Gemini...\")\n",
        "    qa_chain = build_qa_chain(vectorstore)\n",
        "    return qa_chain.run(query)\n",
        "\n",
        "# ---- RUN ----\n",
        "if __name__ == \"__main__\":\n",
        "    user_query = input(\"Ask a medical question: \")\n",
        "    response = answer_question(user_query)\n",
        "    print(\"\\nAnswer:\", response)"
      ]
    }
  ]
}